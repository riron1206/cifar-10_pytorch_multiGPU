{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7643e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timm version: 0.5.5\n",
      "cuda\n",
      "os.environ['CUDA_VISIBLE_DEVICES']: 0,1\n",
      "{'num_workers': 8, 'seeds': [0], 'n_fold': 5, 'n_classes': 10, 'lr': 0.0001, 'min_lr': 1e-06, 'weight_decay': 1e-06, 'optimizer': 'adam', 'scheduler': 'CosineAnnealingLR', 'T_max': 3, 'gradient_accumulation_steps': 1, 'max_grad_norm': 5, 'model_name': 'tf_efficientnet_b7_ns', 'load_model_path': 'none', 'is_load_opt': True, 'epochs': 3, 'print_freq': 10000, 'device_ids': [0, 1], 'batch_size': 256}\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/tf_efficientnet_b7_ns-1dbc32de.pth\" to /root/.cache/torch/hub/checkpoints/tf_efficientnet_b7_ns-1dbc32de.pth\n",
      "=> is_multiGPU [0, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/176] Data 0.049 (0.049) Elapsed 0m 4s (remain 13m 40s) Loss: 2.4065(2.4065) Grad Norm: nan  LR: 1.0000e-04  \n",
      "Epoch: [1][175/176] Data 0.029 (0.048) Elapsed 0m 58s (remain 0m 0s) Loss: 1.6381(1.9520) Grad Norm: 9.0291  LR: 1.0000e-04  \n",
      "EVAL: [0/100] Data 0.015 (0.015) Elapsed 0m 0s (remain 1m 5s) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "labels: [3 8 8 0 6]\n",
      "preds: [9 8 1 8 6]\n",
      "Epoch 1 - avg_train_loss: 1.9520  lr: 1.0000e-04  time: 76s\n",
      "Epoch 1 - Score: 0.4206\n",
      "Epoch 1 - Save Best Score: 0.4206 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [99/100] Data 0.014 (0.014) Elapsed 0m 10s (remain 0m 0s) \n",
      "Epoch: [2][0/176] Data 0.045 (0.045) Elapsed 0m 0s (remain 1m 22s) Loss: 1.6053(1.6053) Grad Norm: 6.9071  LR: 5.6688e-05  \n",
      "Epoch: [2][175/176] Data 0.028 (0.066) Elapsed 0m 56s (remain 0m 0s) Loss: 1.2165(1.3864) Grad Norm: 7.5109  LR: 5.6688e-05  \n",
      "EVAL: [0/100] Data 0.015 (0.015) Elapsed 0m 0s (remain 0m 9s) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "labels: [3 8 8 0 6]\n",
      "preds: [5 8 8 0 6]\n",
      "Epoch 2 - avg_train_loss: 1.3864  lr: 5.6688e-05  time: 71s\n",
      "Epoch 2 - Score: 0.5298\n",
      "Epoch 2 - Save Best Score: 0.5298 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [99/100] Data 0.014 (0.014) Elapsed 0m 9s (remain 0m 0s) \n",
      "Epoch: [3][0/176] Data 0.043 (0.043) Elapsed 0m 0s (remain 0m 54s) Loss: 1.2380(1.2380) Grad Norm: 5.5180  LR: 9.2500e-06  \n",
      "Epoch: [3][175/176] Data 0.028 (0.068) Elapsed 0m 56s (remain 0m 0s) Loss: 1.1763(1.0763) Grad Norm: 9.6154  LR: 9.2500e-06  \n",
      "EVAL: [0/100] Data 0.015 (0.015) Elapsed 0m 0s (remain 0m 9s) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "labels: [3 8 8 0 6]\n",
      "preds: [5 8 8 0 6]\n",
      "Epoch 3 - avg_train_loss: 1.0763  lr: 9.2500e-06  time: 72s\n",
      "Epoch 3 - Score: 0.5580\n",
      "Epoch 3 - Save Best Score: 0.5580 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [99/100] Data 0.014 (0.014) Elapsed 0m 9s (remain 0m 0s) \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9995</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9996</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9997</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9998</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>9999</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  label  pred\n",
       "0        0      3     5\n",
       "1        1      8     8\n",
       "2        2      8     8\n",
       "3        3      0     0\n",
       "4        4      6     6\n",
       "...    ...    ...   ...\n",
       "9995  9995      8     0\n",
       "9996  9996      3     3\n",
       "9997  9997      5     5\n",
       "9998  9998      1     2\n",
       "9999  9999      7     7\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "train finish!!!\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#%%writefile cifar-10_pytorch.py\n",
    "\n",
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import sys\n",
    "import os\n",
    "import gc\n",
    "import re\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import yaml\n",
    "import shutil\n",
    "import glob\n",
    "import pickle\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "from contextlib import contextmanager\n",
    "from collections import defaultdict, Counter, OrderedDict\n",
    "\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD\n",
    "import torchvision.models as models\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import transforms\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence  # 文字列の長さを揃えてくれる関数\n",
    "from torch.optim.lr_scheduler import (\n",
    "    CosineAnnealingWarmRestarts,\n",
    "    CosineAnnealingLR,\n",
    "    ReduceLROnPlateau,\n",
    ")\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "#sys.path.append(r'C:\\Users\\yokoi.shingo\\GitHub\\Ranger-Deep-Learning-Optimizer')\n",
    "#sys.path.append(r'C:\\Users\\yokoi.shingo\\GitHub\\pytorch-optimizer')\n",
    "#from torch_optimizer import RAdam, Lookahead\n",
    "\n",
    "import timm\n",
    "print(\"timm version:\", timm.__version__)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# ====================================================\n",
    "# Helper functions\n",
    "# ====================================================\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return \"%dm %ds\" % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "\n",
    "def train_fn(\n",
    "    train_loader, model, criterion, optimizer, epoch, scheduler, device, scaler\n",
    "):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    start = end = time.time()\n",
    "    global_step = 0\n",
    "    for step, (images, labels) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = images.size(0)\n",
    "        #print(\"images.shape, labels.shape, batch_size:\", images.shape, labels.shape, batch_size)\n",
    "        with autocast():\n",
    "            logits = model(images)\n",
    "            #print(\"logits.shape, logits:\", logits.shape, logits)\n",
    "            loss = criterion(logits, labels)\n",
    "            #print(\"loss:\", loss)\n",
    "            # record loss\n",
    "            losses.update(loss.item(), batch_size)\n",
    "            if CFG.gradient_accumulation_steps > 1:\n",
    "                loss = loss / CFG.gradient_accumulation_steps\n",
    "            scaler.scale(loss).backward()\n",
    "            if (step + 1) % CFG.gradient_accumulation_steps == 0:\n",
    "                scaler.unscale_(optimizer)\n",
    "                grad_norm = torch.nn.utils.clip_grad_norm_(\n",
    "                    model.parameters(), CFG.max_grad_norm, norm_type=2.0\n",
    "                )\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "                global_step += 1\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(train_loader) - 1):\n",
    "            print(\n",
    "                \"Epoch: [{0}][{1}/{2}] \"\n",
    "                \"Data {data_time.val:.3f} ({data_time.avg:.3f}) \"\n",
    "                \"Elapsed {remain:s} \"\n",
    "                \"Loss: {loss.val:.4f}({loss.avg:.4f}) \"\n",
    "                \"Grad Norm: {grad_norm:.4f}  \"\n",
    "                \"LR: {lr:.4e}  \".format(\n",
    "                    epoch + 1,\n",
    "                    step,\n",
    "                    len(train_loader),\n",
    "                    batch_time=batch_time,\n",
    "                    data_time=data_time,\n",
    "                    loss=losses,\n",
    "                    remain=timeSince(start, float(step + 1) / len(train_loader)),\n",
    "                    grad_norm=grad_norm,\n",
    "                    lr=scheduler.get_lr()[0],\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # セッション切れても大丈夫なように都度driveに保存する\n",
    "            torch.save(\n",
    "                {\n",
    "                    \"model\": model.state_dict(),\n",
    "                    \"optimizer\": optimizer.state_dict(),\n",
    "                    \"scheduler\": scheduler.state_dict(),\n",
    "                },\n",
    "                \"per_steps.pth\",\n",
    "            )\n",
    "            shutil.copyfile(\"per_steps.pth\", CP_DIR + f\"/{NAME}_per_steps.pth\")\n",
    "\n",
    "    return losses.avg\n",
    "\n",
    "\n",
    "def valid_fn(valid_loader, model, device):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    # switch to evaluation mode\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    start = end = time.time()\n",
    "    for step, (images, labels) in enumerate(valid_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        images = images.to(device)\n",
    "        batch_size = images.size(0)\n",
    "        with torch.no_grad():\n",
    "            #predictions = model.forward_argmax(images)\n",
    "            predictions = model(images).argmax(1)\n",
    "        pred = predictions.detach().cpu().numpy()\n",
    "        preds.append(pred)\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(valid_loader) - 1):\n",
    "            print(\n",
    "                \"EVAL: [{0}/{1}] \"\n",
    "                \"Data {data_time.val:.3f} ({data_time.avg:.3f}) \"\n",
    "                \"Elapsed {remain:s} \".format(\n",
    "                    step,\n",
    "                    len(valid_loader),\n",
    "                    batch_time=batch_time,\n",
    "                    data_time=data_time,\n",
    "                    remain=timeSince(start, float(step + 1) / len(valid_loader)),\n",
    "                )\n",
    "            )\n",
    "    preds = np.concatenate(preds)\n",
    "    return preds\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# Train loop\n",
    "# ====================================================\n",
    "def train_loop():\n",
    "\n",
    "    # ====================================================\n",
    "    # loader\n",
    "    # ====================================================\n",
    "    train_loader = dm.train_dataloader()\n",
    "    valid_loader = dm.test_dataloader()\n",
    "    valid_labels = np.array(dm.cifar_test.targets)  # dm.cifar_valがおかしいのでtest使う\n",
    "    valid_ids = np.array(range(len(valid_labels)))\n",
    "\n",
    "    # ====================================================\n",
    "    # scheduler\n",
    "    # ====================================================\n",
    "    def get_scheduler(optimizer):\n",
    "        if CFG.scheduler == \"ReduceLROnPlateau\":\n",
    "            scheduler = ReduceLROnPlateau(\n",
    "                optimizer,\n",
    "                mode=\"min\",\n",
    "                factor=CFG.factor,\n",
    "                patience=CFG.patience,\n",
    "                verbose=True,\n",
    "                eps=CFG.eps,\n",
    "            )\n",
    "        elif CFG.scheduler == \"CosineAnnealingLR\":\n",
    "            scheduler = CosineAnnealingLR(\n",
    "                optimizer, T_max=CFG.T_max, eta_min=CFG.min_lr, last_epoch=-1\n",
    "            )\n",
    "        elif CFG.scheduler == \"CosineAnnealingWarmRestarts\":\n",
    "            scheduler = CosineAnnealingWarmRestarts(\n",
    "                optimizer, T_0=CFG.T_0, T_mult=1, eta_min=CFG.min_lr, last_epoch=-1\n",
    "            )\n",
    "        return scheduler\n",
    "\n",
    "    # ====================================================\n",
    "    # model & optimizer\n",
    "    # ====================================================\n",
    "    model = TimmModel(CFG.n_classes, model_name=CFG.model_name, pretrained=True)\n",
    "    model.to(device)\n",
    "    \n",
    "    # https://aru47.hatenablog.com/entry/2020/11/06/225052\n",
    "    if len(CFG.device_ids) > 1:\n",
    "        LOGGER.info(f\"=> is_multiGPU {CFG.device_ids}\")\n",
    "        model = nn.DataParallel(model, device_ids=CFG.device_ids)  # make parallel\n",
    "        cudnn.benchmark = True\n",
    "\n",
    "    if CFG.optimizer == \"adam\":\n",
    "        optimizer = Adam(\n",
    "            model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay, amsgrad=False\n",
    "        )\n",
    "    elif CFG.optimizer == \"radam\":\n",
    "        optimizer = RAdam(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay)\n",
    "        optimizer = Lookahead(optimizer, alpha=0.5, k=5)\n",
    "\n",
    "    scheduler = get_scheduler(optimizer)\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    if os.path.exists(CFG.load_model_path):\n",
    "        # モデルロード\n",
    "        LOGGER.info(\"=> loading checkpoint '{}'\".format(CFG.load_model_path))\n",
    "        states = torch.load(CFG.load_model_path, map_location=torch.device(\"cpu\"))\n",
    "        model.load_state_dict(states[\"model\"])\n",
    "        model.to(device)\n",
    "        if CFG.is_load_opt:\n",
    "            LOGGER.info(\"=> loading optimizer and scheduler\")\n",
    "            optimizer.load_state_dict(states[\"optimizer\"])\n",
    "            scheduler.load_state_dict(states[\"scheduler\"])\n",
    "\n",
    "    # ====================================================\n",
    "    # loop\n",
    "    # ====================================================\n",
    "    criterion = nn.CrossEntropyLoss()  # loss計算したくないクラスは, ignore_index=1 で指定できる\n",
    "\n",
    "    best_score = -1  # np.inf\n",
    "\n",
    "    for epoch in range(CFG.epochs):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # train\n",
    "        avg_loss = train_fn(\n",
    "            train_loader, model, criterion, optimizer, epoch, scheduler, device, scaler\n",
    "        )\n",
    "\n",
    "        # eval\n",
    "        preds = valid_fn(valid_loader, model, device)\n",
    "        LOGGER.info(f\"labels: {valid_labels[:5]}\")\n",
    "        LOGGER.info(f\"preds: {preds[:5]}\")\n",
    "\n",
    "        # scoring\n",
    "        score = get_score(valid_labels, preds)\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        LOGGER.info(\n",
    "            f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  lr: {scheduler.get_lr()[0]:.4e}  time: {elapsed:.0f}s\"\n",
    "        )\n",
    "        LOGGER.info(f\"Epoch {epoch+1} - Score: {score:.4f}\")\n",
    "\n",
    "        if isinstance(scheduler, ReduceLROnPlateau):\n",
    "            scheduler.step(score)\n",
    "        elif isinstance(scheduler, CosineAnnealingLR):\n",
    "            scheduler.step()\n",
    "        elif isinstance(scheduler, CosineAnnealingWarmRestarts):\n",
    "            scheduler.step()\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            LOGGER.info(f\"Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model\")\n",
    "            best_pth = OUTPUT_DIR + f\"/{NAME}_best.pth\"\n",
    "            #torch.save(\n",
    "            #    {\n",
    "            #        \"model\": model.state_dict(),\n",
    "            #        \"optimizer\": optimizer.state_dict(),\n",
    "            #        \"scheduler\": scheduler.state_dict(),\n",
    "            #        \"preds\": preds,\n",
    "            #    },\n",
    "            #    best_pth,\n",
    "            #)\n",
    "            val_pred_df = pd.DataFrame(\n",
    "                {\"id\": valid_ids, \"label\": valid_labels, \"pred\": preds}\n",
    "            )\n",
    "            #val_pred_df.to_csv(CP_DIR + f\"/{NAME}_val_pred.csv\", index=False)\n",
    "            #\n",
    "            ## セッション切れても大丈夫なように都度driveに保存する\n",
    "            #shutil.copyfile(\n",
    "            #    best_pth, CP_DIR + f\"/{NAME}_\" + Path(best_pth).name\n",
    "            #)\n",
    "            #shutil.copyfile(OUTPUT_DIR + \"/train.log\", CP_DIR + f\"/{NAME}_train.log\")\n",
    "    \n",
    "    return val_pred_df\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "# ====================================================\n",
    "# Utils\n",
    "# ====================================================\n",
    "def get_score(y_true, y_pred):\n",
    "    return accuracy_score(y_true, y_pred)\n",
    "\n",
    "\n",
    "def init_logger(log_file='train.log'):\n",
    "    \"\"\"\n",
    "    学習ログファイル出す\n",
    "    \"\"\"\n",
    "    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "\n",
    "def seed_torch(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# Model\n",
    "# ====================================================\n",
    "class TimmModel(nn.Module):\n",
    "    def __init__(self, n_classes, model_name=\"resnet18\", pretrained=True):\n",
    "        super().__init__()\n",
    "        self.cnn = timm.create_model(model_name, pretrained=pretrained)\n",
    "        if \"efficient\" in model_name:\n",
    "            self.cnn.classifier = nn.Linear(self.cnn.classifier.in_features, n_classes)\n",
    "        elif \"vit\" in model_name:\n",
    "            self.cnn.head = nn.Linear(self.cnn.head.in_features, n_classes)\n",
    "        elif \"nfnet\" in model_name:\n",
    "            self.cnn.head.fc = nn.Linear(self.cnn.head.fc.in_features, n_classes)\n",
    "        else:\n",
    "            self.cnn.fc = nn.Linear(self.cnn.fc.in_features, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.cnn(x)\n",
    "    \n",
    "    def forward_argmax(self, x):\n",
    "        return self.cnn(x).argmax(1)\n",
    "        \n",
    "\n",
    "# ====================================================\n",
    "# Data Load\n",
    "# ====================================================\n",
    "# cifar10 ---------------\n",
    "class CIFAR10DataModule():\n",
    "    def __init__(self, batch_size=512, data_dir: str = \"./\"):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),])\n",
    "        self.dims = (3, 32, 32)\n",
    "        self.num_classes = 10\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # download\n",
    "        CIFAR10(self.data_dir, train=True, download=True)\n",
    "        CIFAR10(self.data_dir, train=False, download=True)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # Assign train/val datasets for use in dataloaders\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            cifar_full = CIFAR10(self.data_dir, train=True, transform=self.transform)\n",
    "            self.cifar_train, self.cifar_val = random_split(cifar_full, [45000, 5000])\n",
    "\n",
    "        # Assign test dataset for use in dataloader(s)\n",
    "        if stage == \"test\" or stage is None:\n",
    "            self.cifar_test = CIFAR10(\n",
    "                self.data_dir, train=False, transform=self.transform\n",
    "            )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.cifar_train, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.cifar_val, batch_size=100)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.cifar_test, batch_size=100)\n",
    "\n",
    "\n",
    "# https://github.com/sinpcw/kaggle-whale2/blob/master/models.py\n",
    "def loadpth(pth: str, map_location=None) -> OrderedDict:\n",
    "    \"\"\"\n",
    "    パラメータロードのヘルパー関数.\n",
    "    DataParallel化したモデルは module.xxxx という形式で保存されるため読込み時にmodule.から始まる場合はそれを取除く.\n",
    "    \"\"\"\n",
    "    ostate = torch.load(pth, map_location=map_location)\n",
    "    nstate = OrderedDict()\n",
    "    for k, v in ostate.items():\n",
    "        if k.startswith('module.'):\n",
    "            nstate[k[len('module.'):]] = v\n",
    "        else:\n",
    "            nstate[k] = v\n",
    "    return nstate\n",
    "\n",
    "    \n",
    "# ====================================================\n",
    "# Param\n",
    "# ====================================================\n",
    "CP_DIR = \"output\"\n",
    "OUTPUT_DIR = \".\"\n",
    "os.makedirs(CP_DIR, exist_ok=True)\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "NAME = \"cifar10\"\n",
    "\n",
    "epochs = 3\n",
    "class Config:\n",
    "    def __init__(self):  # init__()に変数入れないと、CFG.__dict__したに型がすべて文字列になってしまう\n",
    "        self.num_workers = 8  # os.cpu_count()\n",
    "        self.seeds = [0]\n",
    "        self.n_fold = 5\n",
    "        self.n_classes = 10  # len(set(train[\"label\"].values))  # 回帰にする場合は、Dataloaderのラベルの型をfloatにする + loss と score の式を nn.MSELoss とかにする + valid の model.forward_argmax() を  model() にする\n",
    "        self.lr = 1e-4\n",
    "        self.min_lr = 1e-6\n",
    "        self.weight_decay = 1e-6\n",
    "        self.optimizer = \"adam\"\n",
    "        self.scheduler = \"CosineAnnealingLR\"  # ['ReduceLROnPlateau', 'CosineAnnealingLR', 'CosineAnnealingWarmRestarts']\n",
    "        self.T_max = epochs  # CosineAnnealingLR\n",
    "        self.gradient_accumulation_steps = 1\n",
    "        self.max_grad_norm = 5\n",
    "        #self.model_name = \"resnet18\"\n",
    "        #self.model_name = \"resnet101\"\n",
    "        self.model_name = \"tf_efficientnet_b7_ns\"\n",
    "        #self.model_name = \"tf_efficientnet_l2_ns\"\n",
    "        self.load_model_path = \"none\"\n",
    "        #self.load_model_path = \"fold0_best.pth\"\n",
    "        self.is_load_opt = True\n",
    "        self.epochs = epochs\n",
    "        self.print_freq = 10000  # 学習結果をprintするstep数\n",
    "        self.device_ids = [0,1]\n",
    "        #self.batch_size = 512\n",
    "        self.batch_size = 128\n",
    "CFG = Config()\n",
    "\n",
    "if len(CFG.device_ids) > 1:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \",\".join([str(_) for _ in CFG.device_ids])\n",
    "    print(\"os.environ['CUDA_VISIBLE_DEVICES']:\", os.environ[\"CUDA_VISIBLE_DEVICES\"])\n",
    "    CFG.batch_size = CFG.batch_size*2\n",
    "print(CFG.__dict__)\n",
    "\n",
    "with open(\"cfg.yaml\", \"w\") as wf:\n",
    "    yaml.dump(CFG.__dict__, wf)\n",
    "shutil.copyfile(\"cfg.yaml\", CP_DIR+f\"/{NAME}_cfg.yaml\")\n",
    "\n",
    "# ====================================================\n",
    "# Data\n",
    "# ====================================================\n",
    "dm = CIFAR10DataModule(batch_size=CFG.batch_size)\n",
    "dm.prepare_data()\n",
    "dm.setup()\n",
    "n_classes = dm.num_classes\n",
    "\n",
    "# ====================================================\n",
    "# LOGGER\n",
    "# ====================================================\n",
    "LOGGER = init_logger(OUTPUT_DIR + \"/train.log\")\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# main\n",
    "# ====================================================\n",
    "def main():\n",
    "    for seed in CFG.seeds:\n",
    "        seed_torch(seed=seed)\n",
    "\n",
    "        val_pred_df = train_loop()\n",
    "        val_pred_df.to_csv(CP_DIR + f\"{NAME}_val_pred_seed{seed}.csv\", index=False)\n",
    "        display(val_pred_df)\n",
    "        \n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    \n",
    "LOGGER.info(\"\\ntrain finish!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52df7e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!CUDA_VISIBLE_DEVICES=0,1 python cifar-10_pytorch.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8d3d66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf228e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch: [1][0/88] Data 0.132 (0.132) Elapsed 0m 3s (remain 4m 29s) Loss: 2.3471(2.3471) Grad Norm: nan  LR: 1.0000e-04  \n",
      "Epoch: [1][87/88] Data 0.065 (0.094) Elapsed 0m 38s (remain 0m 0s) Loss: 1.8541(2.0792) Grad Norm: 15.4361  LR: 1.0000e-04  \n",
      "EVAL: [0/100] Data 0.015 (0.015) Elapsed 0m 0s (remain 1m 9s) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "labels: [3 8 8 0 6]\n",
      "preds: [5 9 8 9 3]\n",
      "Epoch 1 - avg_train_loss: 2.0792  lr: 1.0000e-04  time: 52s\n",
      "Epoch 1 - Score: 0.3477\n",
      "Epoch 1 - Save Best Score: 0.3477 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [99/100] Data 0.014 (0.014) Elapsed 0m 7s (remain 0m 0s) \n",
      "Epoch: [2][0/88] Data 0.087 (0.087) Elapsed 0m 0s (remain 0m 35s) Loss: 1.7268(1.7268) Grad Norm: 11.8674  LR: 5.6688e-05  \n",
      "Epoch: [2][87/88] Data 0.066 (0.135) Elapsed 0m 36s (remain 0m 0s) Loss: 1.4726(1.6070) Grad Norm: 6.7869  LR: 5.6688e-05  \n",
      "EVAL: [0/100] Data 0.016 (0.016) Elapsed 0m 0s (remain 0m 7s) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "labels: [3 8 8 0 6]\n",
      "preds: [5 8 8 8 6]\n",
      "Epoch 2 - avg_train_loss: 1.6070  lr: 5.6688e-05  time: 49s\n",
      "Epoch 2 - Score: 0.4465\n",
      "Epoch 2 - Save Best Score: 0.4465 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [99/100] Data 0.014 (0.014) Elapsed 0m 6s (remain 0m 0s) \n",
      "Epoch: [3][0/88] Data 0.088 (0.088) Elapsed 0m 0s (remain 0m 33s) Loss: 1.3659(1.3659) Grad Norm: 12.9139  LR: 9.2500e-06  \n",
      "Epoch: [3][87/88] Data 0.066 (0.137) Elapsed 0m 36s (remain 0m 0s) Loss: 1.3561(1.3117) Grad Norm: 8.4783  LR: 9.2500e-06  \n",
      "EVAL: [0/100] Data 0.015 (0.015) Elapsed 0m 0s (remain 0m 7s) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "labels: [3 8 8 0 6]\n",
      "preds: [5 8 8 8 6]\n",
      "Epoch 3 - avg_train_loss: 1.3117  lr: 9.2500e-06  time: 50s\n",
      "Epoch 3 - Score: 0.4674\n",
      "Epoch 3 - Save Best Score: 0.4674 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [99/100] Data 0.014 (0.014) Elapsed 0m 6s (remain 0m 0s) \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9995</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9996</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9997</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9998</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>9999</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  label  pred\n",
       "0        0      3     5\n",
       "1        1      8     8\n",
       "2        2      8     8\n",
       "3        3      0     8\n",
       "4        4      6     6\n",
       "...    ...    ...   ...\n",
       "9995  9995      8     0\n",
       "9996  9996      3     3\n",
       "9997  9997      5     5\n",
       "9998  9998      1     2\n",
       "9999  9999      7     7\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "train finish!!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 20s, sys: 20.3 s, total: 2min 40s\n",
      "Wall time: 2min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "CFG.device_ids = [0]\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "CFG.batch_size = 512\n",
    "\n",
    "dm = CIFAR10DataModule(batch_size=CFG.batch_size)\n",
    "dm.prepare_data()\n",
    "dm.setup()\n",
    "n_classes = dm.num_classes\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    \n",
    "LOGGER.info(\"\\ntrain finish!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "285cec06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=> is_multiGPU [0, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/44] Data 0.216 (0.216) Elapsed 0m 3s (remain 2m 21s) Loss: 2.3448(2.3448) Grad Norm: nan  LR: 1.0000e-04  \n",
      "Epoch: [1][43/44] Data 0.125 (0.185) Elapsed 0m 30s (remain 0m 0s) Loss: 2.0220(2.1699) Grad Norm: 11.2781  LR: 1.0000e-04  \n",
      "EVAL: [0/100] Data 0.015 (0.015) Elapsed 0m 0s (remain 0m 9s) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "labels: [3 8 8 0 6]\n",
      "preds: [5 8 1 8 6]\n",
      "Epoch 1 - avg_train_loss: 2.1699  lr: 1.0000e-04  time: 46s\n",
      "Epoch 1 - Score: 0.2518\n",
      "Epoch 1 - Save Best Score: 0.2518 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [99/100] Data 0.016 (0.014) Elapsed 0m 9s (remain 0m 0s) \n",
      "Epoch: [2][0/44] Data 0.195 (0.195) Elapsed 0m 0s (remain 0m 25s) Loss: 1.9445(1.9445) Grad Norm: 9.4949  LR: 5.6688e-05  \n",
      "Epoch: [2][43/44] Data 0.134 (0.263) Elapsed 0m 27s (remain 0m 0s) Loss: 1.7242(1.8052) Grad Norm: 11.5136  LR: 5.6688e-05  \n",
      "EVAL: [0/100] Data 0.014 (0.014) Elapsed 0m 0s (remain 0m 14s) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "labels: [3 8 8 0 6]\n",
      "preds: [8 8 8 8 2]\n",
      "Epoch 2 - avg_train_loss: 1.8052  lr: 5.6688e-05  time: 42s\n",
      "Epoch 2 - Score: 0.3722\n",
      "Epoch 2 - Save Best Score: 0.3722 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [99/100] Data 0.014 (0.014) Elapsed 0m 9s (remain 0m 0s) \n",
      "Epoch: [3][0/44] Data 0.217 (0.217) Elapsed 0m 0s (remain 0m 24s) Loss: 1.5841(1.5841) Grad Norm: 9.3706  LR: 9.2500e-06  \n",
      "Epoch: [3][43/44] Data 0.137 (0.268) Elapsed 0m 27s (remain 0m 0s) Loss: 1.5785(1.5692) Grad Norm: 7.8752  LR: 9.2500e-06  \n",
      "EVAL: [0/100] Data 0.015 (0.015) Elapsed 0m 0s (remain 0m 9s) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "labels: [3 8 8 0 6]\n",
      "preds: [5 8 9 8 6]\n",
      "Epoch 3 - avg_train_loss: 1.5692  lr: 9.2500e-06  time: 42s\n",
      "Epoch 3 - Score: 0.3934\n",
      "Epoch 3 - Save Best Score: 0.3934 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [99/100] Data 0.014 (0.014) Elapsed 0m 9s (remain 0m 0s) \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9995</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9996</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9997</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9998</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>9999</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  label  pred\n",
       "0        0      3     5\n",
       "1        1      8     8\n",
       "2        2      8     9\n",
       "3        3      0     8\n",
       "4        4      6     6\n",
       "...    ...    ...   ...\n",
       "9995  9995      8     8\n",
       "9996  9996      3     3\n",
       "9997  9997      5     3\n",
       "9998  9998      1     7\n",
       "9999  9999      7     7\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "train finish!!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 33s, sys: 19.2 s, total: 2min 52s\n",
      "Wall time: 2min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "CFG.device_ids = [0,1]\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "CFG.batch_size = 512*2\n",
    "\n",
    "dm = CIFAR10DataModule(batch_size=CFG.batch_size)\n",
    "dm.prepare_data()\n",
    "dm.setup()\n",
    "n_classes = dm.num_classes\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    \n",
    "LOGGER.info(\"\\ntrain finish!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2caa7dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e1fb537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "==> Making model..\n",
      "The number of parameters of model is 23528522\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_65791/1852865630.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_65791/1852865630.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(batch_size, device_ids)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m#                       momentum=0.9, weight_decay=1e-4)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "# https://www.programcreek.com/python/example/107676/torch.nn.DataParallel\n",
    "def main(batch_size=512, device_ids=[0]):\n",
    "    best_acc = 0\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    print('==> Preparing data..')\n",
    "    transforms_train = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "    dataset_train = CIFAR10(root='.', train=True, download=True, \n",
    "                            transform=transforms_train)\n",
    "\n",
    "    train_loader = DataLoader(dataset_train, batch_size=batch_size, \n",
    "                              shuffle=True, num_workers=8)\n",
    "\n",
    "    # there are 10 classes so the dataset name is cifar-10\n",
    "    classes = ('plane', 'car', 'bird', 'cat', 'deer', \n",
    "               'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "    print('==> Making model..')\n",
    "\n",
    "    net = TimmModel(10, model_name=\"resnet50\", pretrained=True)\n",
    "    net.to(device)\n",
    "    \n",
    "    if len(device_ids) > 1:\n",
    "        net = nn.DataParallel(net, device_ids=device_ids)\n",
    "        net = net.to(device)\n",
    "    \n",
    "    num_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "    print('The number of parameters of model is', num_params)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(net.parameters(), lr=1e-3)\n",
    "    # optimizer = SGD(net.parameters(), lr=1e-3, \n",
    "    #                       momentum=0.9, weight_decay=1e-4)\n",
    "    \n",
    "    train(net, criterion, optimizer, train_loader, device) \n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461dd884",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba99d89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
